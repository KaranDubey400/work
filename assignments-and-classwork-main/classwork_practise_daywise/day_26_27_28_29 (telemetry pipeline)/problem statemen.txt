You will build a 3-process telemetry pipeline that simulates a real system:
 
Generator creates telemetry events and writes them to a file continuously
 
Analyzer reads the file stream and publishes recent events + stats into shared memory
 
Monitor reads shared memory and prints real-time statistics

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=
 
This is an IPC + synchronization + data-structure exercise using:
 
File I/O (append + streaming read)
 
POSIX shared memory (shm_open, mmap)
 
Process-shared locking (pthread_mutex / pthread_rwlock)
 
A shared linked list stored in shared memory (index-based nodes, no pointers)
 
event_id (uint64)
 
sensor_id (uint32) — range: 1..64
 
timestamp_ns (uint64) — monotonic or realtime
 
value (double)
 
severity (uint8) — range: 0..5
 
Continuously generate events (random but reasonable values).
 
Append events to a file named: telemetry.bin
 
Write at a configurable rate (default: 100 events/second).
 
Each write must be record framed so the analyzer never reads “half a record”.
 
Open and read telemetry.bin as a stream (like tailing a log).
 
Parse records and publish them into POSIX shared memory.
 
In shared memory, maintain:
 
A linked list of the most recent events (bounded size)
 
Rolling statistics updated in real time
 
The analyzer must be the only writer to shared memory.
 
Shared Memory Name
 
Use a shared memory object named: /telemetry_shm
 
Bounded List Requirements
 
Keep only the last MAX_EVENTS = 2000 events in the shared list.
 
When list exceeds MAX_EVENTS, evict from the head (oldest first).
 
Rolling Stats Requirements
 
Maintain these stats (at least):
 
Total events processed
 
Per-sensor:
 
count
 
average value (or sum + count)
 
min value
 
max value
 
max severity seen
 
Correctness Requirements
 
Analyzer must not corrupt shared memory under load.
 
Must handle partial reads: if it reads an incomplete record, it must wait for the rest.
 
Requirements
 
Attach to /telemetry_shm read-only (or normal attach but do not write).
 
Every 500 ms print real-time stats:
 
total events
 
top 5 sensors by count (or any meaningful ranking)
 
overall max severity
 
last event timestamp / last event_id (optional but recommended)
 
Must run concurrently with analyzer without crashing or printing junk
 
Shared memory Rule: No heap pointers inside shared memory
 
You must implement the shared linked list using:
 
an array nodes[MAX_NODES]
 
next_idx (integer index), NOT pointers
 
Node Pool (Allocator)
 
Pre-allocate MAX_NODES = 4096 nodes in shared memory.
 
Maintain a free-list of available nodes (by index).
 
Analyzer allocates from free-list when adding a node.
 
When evicting/deleting, return node index back to free-list.
 
 
 
Synchronization Rules

Requirements
 
Shared memory must include:
 
One process-shared RW lock for list + stats consistency
 
One process-shared mutex for the free-list allocator
 
Locking rules:
 
Monitor uses read lock while reading stats / list
 
Analyzer uses write lock while updating stats / list
 
Free-list operations must be protected by allocator mutex
 
Use a fixed lock order (to avoid deadlocks), e.g.:
 
acquire list lock → then allocator lock (if needed)
 
Shutdown Rules
 
Shared memory includes a shutdown flag.
 
Processes should exit cleanly when shutdown is set (or on SIGINT).
 
Analyzer should create/initialize shared memory if not present.
 
Monitor should wait/retry until shared memory appears (do not crash immediately).
 
Testing Rules
Run all 3 processes for 2 minutes:
 
no deadlocks
 
no memory corruption
 
stable stats output
 
Generator file grows as expected
 
Analyzer keeps list bounded at MAX_EVENTS
 
Monitor output updates roughly in real time
 
Clean shutdown works (Ctrl+C)
 